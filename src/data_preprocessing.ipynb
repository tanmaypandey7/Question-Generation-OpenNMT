{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nw0vbLvpIDoa"
   },
   "source": [
    "### Link:https://www.tensorflow.org/beta/tutorials/text/nmt_with_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "xT1xR6wjX5aZ",
    "outputId": "4a6f8237-bf84-4d9e-d009-bd312cfafa8e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
    "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMBysc9BYwWE"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"/home/tanmay/Documents/squad 1.1/json_format/stanford-question-answering-dataset/train-v1.1.json\")\n",
    "dev = pd.read_json(\"/home/tanmay/Documents/squad 1.1/json_format/stanford-question-answering-dataset/dev-v1.1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANFORD_DATA_PATH = \"/home/tanmay/Documents/squad 1.1/json_format/stanford-question-answering-dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_off_corrections(df):\n",
    "    \"\"\"\n",
    "    some specific corrections, simplifications, etc -- plus some manual copy/paste issues make certain\n",
    "    answers hard to parse\n",
    "\n",
    "    it looks like answer_start was determined by a blind search for first occurrence of the answer string.\n",
    "    possible there are systematic issues with this value throughout the dataset that weren't caught by\n",
    "    the answer validation used here\n",
    "\n",
    "    TODO: possibly just save / reupload data with these corrections made\n",
    "    \"\"\"\n",
    "    for idx in range(df.shape[0]):\n",
    "        answer = df.loc[idx, 'text']\n",
    "        if answer.startswith(\". \") or answer.startswith(\", \"):\n",
    "            df.loc[idx, 'text'] = answer[2:]\n",
    "            df.loc[idx, 'answer_start'] += 2\n",
    "\n",
    "    for _ in range(0, 5):\n",
    "        df = df.drop(16818 + _)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    for _ in range(0, 4):\n",
    "        df = df.drop(38416 + _)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    # person could not come up with questions and entered junk data\n",
    "    df = df.drop(38537)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(38666)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(38693)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df.loc[1590, 'answer_start'] = 332\n",
    "    df.loc[1590, 'text'] = 'seven'\n",
    "\n",
    "    df.loc[1595, 'answer_start'] = 332\n",
    "    df.loc[1595, 'text'] = 'seven'\n",
    "\n",
    "    df.loc[1600, 'answer_start'] = 332\n",
    "    df.loc[1600, 'text'] = 'seven'\n",
    "\n",
    "    df.loc[2478, 'answer_start'] = 302\n",
    "    df.loc[2478, 'text'] = 'three'\n",
    "\n",
    "    df.loc[2491, 'answer_start'] = 60\n",
    "    df.loc[\n",
    "        2491, 'text'] = \"the media player included with the iPhone and iPad, a combination of the Music and Videos apps\"\n",
    "\n",
    "    df.loc[2501, 'answer_start'] = 396\n",
    "\n",
    "    df.loc[3215, 'answer_start'] = 242\n",
    "    df.loc[3218, 'answer_start'] = 242\n",
    "\n",
    "    df.loc[3472, 'answer_start'] = 242\n",
    "\n",
    "    df.loc[3490, 'text'] = \"a million\"\n",
    "    df.loc[3490, 'answer_start'] = 268\n",
    "\n",
    "    df.loc[4051, 'text'] = \"over 50\"\n",
    "    df.loc[4051, 'answer_start'] = 327\n",
    "\n",
    "    df.loc[4168, 'text'] = \"92%\"\n",
    "    df.loc[4168, 'answer_start'] = 444\n",
    "\n",
    "    df.loc[4182, 'answer_start'] = 618\n",
    "\n",
    "    df.loc[5121, 'text'] = \"15 km southwest of Dushanbe\"\n",
    "    df.loc[5121, 'answer_start'] = 499\n",
    "\n",
    "    df.loc[5919, 'text'] = \"seventh\"\n",
    "    df.loc[5919, 'answer_start'] = 983\n",
    "\n",
    "    df.loc[5924, 'text'] = \"seventh\"\n",
    "    df.loc[5924, 'answer_start'] = 983\n",
    "\n",
    "    df.loc[5990, 'text'] = \"three\"\n",
    "    df.loc[5990, 'answer_start'] = 925\n",
    "\n",
    "    df.loc[5992, 'text'] = \"three\"\n",
    "    df.loc[5992, 'answer_start'] = 925\n",
    "\n",
    "    df.loc[6314, 'text'] = \"six\"\n",
    "    df.loc[6314, 'answer_start'] = 292\n",
    "\n",
    "    df.loc[6316, 'text'] = \"six\"\n",
    "    df.loc[6316, 'answer_start'] = 13\n",
    "\n",
    "    df.loc[6735, 'answer_start'] = 118\n",
    "\n",
    "    df.loc[6769, 'answer_start'] = 513\n",
    "    df.loc[6769, 'text'] = \"ritual, visualization, physical exercises, and meditation\"\n",
    "\n",
    "    df.loc[6985, 'answer_start'] = 333\n",
    "    df.loc[6985, 'text'] = \"fifteenth\"\n",
    "\n",
    "    df.loc[7528, 'answer_start'] = 39\n",
    "    df.loc[7528, 'text'] = \"fifteenth\"\n",
    "\n",
    "    df.loc[7529, 'answer_start'] = 326\n",
    "    df.loc[7529, 'text'] = \"fifth\"\n",
    "\n",
    "    df.loc[7622, 'answer_start'] = 411\n",
    "    df.loc[7622, 'text'] = \"fifteenth\"\n",
    "\n",
    "    df.loc[7625, 'answer_start'] = 388\n",
    "    df.loc[7625, 'text'] = \"almost a decade, from 2003 to 2012\"\n",
    "\n",
    "    df.loc[7626, 'answer_start'] = 148\n",
    "    df.loc[7626, 'text'] = \"eight\"\n",
    "\n",
    "    df.loc[7676, 'answer_start'] = 87\n",
    "    df.loc[7676, 'text'] = \"nine\"\n",
    "\n",
    "    df.loc[7676, 'answer_start'] = 113\n",
    "    df.loc[7676, 'text'] = \"Director Bruce Gower won a Primetime Emmy Award for Outstanding Directing For A Variety, Music Or Comedy Series in 2009, and the show won a Creative Arts Emmys each in 2007 and 2008, three in 2009, and two in 2011\"\n",
    "    df.loc[7678, 'answer_start'] = 113\n",
    "    df.loc[7678, 'text'] = \"Director Bruce Gower won a Primetime Emmy Award for Outstanding Directing For A Variety, Music Or Comedy Series in 2009, and the show won a Creative Arts Emmys each in 2007 and 2008, three in 2009, and two in 2011\"\n",
    "\n",
    "    df.loc[8189, 'answer_start'] = 310\n",
    "\n",
    "    df.loc[8735, 'answer_start'] = 137\n",
    "    df.loc[8735, 'text'] = \"its synthesis of and reaction to the world around it\"\n",
    "\n",
    "    df.loc[8835, 'answer_start'] = 373\n",
    "    df.loc[8835, 'text'] = \"300 of which was paid by Cambridge University Press, 200 by the Royal Society of London, and 50 apiece by Whitehead and Russell themselves\"\n",
    "\n",
    "    df.loc[9745, 'answer_start'] = 621\n",
    "\n",
    "    df.loc[10227, 'answer_start'] = 81\n",
    "\n",
    "    df.loc[10354, 'answer_start'] = 326\n",
    "    df.loc[10354, 'text'] = 'one regiment each of artillery, armour, and combat engineers'\n",
    "\n",
    "    df.loc[11780, 'answer_start'] = 239\n",
    "    df.loc[11780, 'text'] = '30'\n",
    "\n",
    "    df.loc[12189, 'answer_start'] = 96\n",
    "    df.loc[12189, 'text'] = 'two'\n",
    "\n",
    "    df.loc[12874, 'answer_start'] = 154\n",
    "    df.loc[12874, 'text'] = 'five'\n",
    "\n",
    "    df.loc[13060, 'answer_start'] = 272\n",
    "\n",
    "    df.loc[13232, 'answer_start'] = 505\n",
    "\n",
    "    df.loc[13787, 'answer_start'] = 362\n",
    "    df.loc[13787, 'text'] = 'nine'\n",
    "\n",
    "    df.loc[13791, 'answer_start'] = 189\n",
    "    df.loc[13791, 'text'] = 'three'\n",
    "\n",
    "    df.loc[13799, 'answer_start'] = 944\n",
    "    df.loc[13799, 'text'] = 'four'\n",
    "\n",
    "    df.loc[13863, 'answer_start'] = 185\n",
    "    df.loc[13863, 'text'] = 'I, II and III'\n",
    "\n",
    "    df.loc[14377, 'answer_start'] = 65\n",
    "    df.loc[14377, 'text'] = 'one'\n",
    "\n",
    "    df.loc[14448, 'answer_start'] = 78\n",
    "    df.loc[14448, 'text'] = 'three'\n",
    "\n",
    "    df.loc[14473, 'answer_start'] = 259\n",
    "    df.loc[14473, 'text'] = '⟨p⟩'\n",
    "\n",
    "    df.loc[14516, 'answer_start'] = 341\n",
    "\n",
    "    df.loc[14582, 'answer_start'] = 12\n",
    "    df.loc[14582, 'text'] = 'two'\n",
    "\n",
    "    df.loc[14589, 'answer_start'] = 674\n",
    "    df.loc[14589, 'text'] = \"partial negative\"\n",
    "\n",
    "    df.loc[15159, 'answer_start'] = 108\n",
    "\n",
    "    df.loc[15246, 'answer_start'] = 186\n",
    "\n",
    "    df.loc[15865, 'text'] = 'i'\n",
    "    df.loc[15865, 'answer_start'] = 231\n",
    "\n",
    "    df.loc[15951, 'text'] = 'one'\n",
    "    df.loc[15951, 'answer_start'] = 114\n",
    "\n",
    "    df.loc[16124, 'answer_start'] = 85\n",
    "\n",
    "    df.loc[16297, 'answer_start'] = 121\n",
    "\n",
    "    df.loc[17106, 'answer_start'] = 200\n",
    "    df.loc[17111, 'answer_start'] = 413\n",
    "\n",
    "    df.loc[17168, 'text'] = 'eight'\n",
    "    df.loc[17168, 'answer_start'] = 63\n",
    "\n",
    "    df.loc[17280, 'answer_start'] = 151\n",
    "\n",
    "    df.loc[18256, 'answer_start'] = 228\n",
    "\n",
    "    df.loc[18369, 'answer_start'] = 370\n",
    "    df.loc[18369, 'text'] = 'ser'\n",
    "\n",
    "    df.loc[18707, 'answer_start'] = 0\n",
    "\n",
    "    df.loc[23848, 'answer_start'] = 3\n",
    "    df.loc[23848, 'text'] = 'the 1950s'\n",
    "\n",
    "    df.loc[25521, 'answer_start'] = 418\n",
    "    df.loc[25521, 'text'] = 'sync word'\n",
    "    ##\n",
    "    df.loc[27972, 'answer_start'] = 111\n",
    "    df.loc[27972, 'text'] = 'the difficulty of the elements the gymnast attempts and whether or not the gymnast meets composition requirements'\n",
    "    df.loc[27972, 'question'] = 'How is the start value determined?'\n",
    "\n",
    "    df.loc[28010, 'answer_start'] = 116\n",
    "    df.loc[28010, 'text'] = 'external force which the gymnasts have to overcome with their muscle force and has an impact on the gymnasts linear and angular momentum'\n",
    "\n",
    "    df.loc[34600, 'answer_start'] = 404\n",
    "    df.loc[34600, 'text'] = 'Men did not show any sexual arousal to non-human visual stimuli'\n",
    "\n",
    "    df.loc[36071, 'answer_start'] = 222\n",
    "    df.loc[36071, 'text'] = 'the information must be changed'\n",
    "\n",
    "    df.loc[39349, 'answer_start'] = 40\n",
    "    df.loc[39349, 'text'] = 'a US$5 million grant for the International Justice Mission (IJM)'\n",
    "\n",
    "    df.loc[45018, 'answer_start'] = 454\n",
    "    df.loc[45018, 'text'] = 'because Florida had become \"a derelict open to the occupancy of every enemy, civilized or savage, of the United States, and serving no other earthly purpose than as a post of annoyance to them.'\n",
    "\n",
    "    df.loc[38536, 'answer_start'] = 491\n",
    "    df.loc[38536, 'question'] = 'How long did the Rhodians hold out under siege by Demetrius Poliorcetes?'\n",
    "    df.loc[38536, 'text'] = 'one year'\n",
    "\n",
    "    df.loc[45076, 'answer_start'] = 562\n",
    "    df.loc[45076, 'text'] = 'the first post-Reconstruction Republican governor'\n",
    "\n",
    "    df.loc[45077, 'answer_start'] = 703\n",
    "    df.loc[45077, 'text'] = \"the state's first post-reconstruction Republican US Senator\"\n",
    "\n",
    "    df.loc[47651, 'answer_start'] = 208\n",
    "    df.loc[47651, 'text'] = 'increasing numbers of airlines have began launching direct flights'\n",
    "\n",
    "    df.loc[52335, 'answer_start'] = 147\n",
    "    df.loc[52335, 'text'] = 'Mahmoud Massahi'\n",
    "\n",
    "    df.loc[53520, 'answer_start'] = 197\n",
    "    df.loc[53520, 'question'] = 'How many days after the Soviet Union issued their ultimatum did the Romanians meet their demands?'\n",
    "    df.loc[53520, 'text'] = 'Two'\n",
    "\n",
    "    df.loc[55205, 'answer_start'] = 48\n",
    "    df.loc[55205, 'text'] = 'the rebuilt Wembley Stadium'\n",
    "\n",
    "    df.loc[55752, 'answer_start'] = 370\n",
    "    df.loc[55752, 'text'] = 'lower-elevation areas of the Piedmont'\n",
    "\n",
    "    df.loc[56306, 'answer_start'] = 506\n",
    "    df.loc[56306, 'text'] = 'the wings of flightless birds and the rudiments of pelvis and leg bones found in some snakes'\n",
    "\n",
    "    df.loc[57712, 'answer_start'] = 78\n",
    "    df.loc[57712, 'text'] = 'vinyl'\n",
    "\n",
    "    df.loc[58754, 'answer_start'] = 35\n",
    "    df.loc[58754, 'text'] = 'the evolving relationship between state governments and the federal government of the United States'\n",
    "\n",
    "    df.loc[58813, 'answer_start'] = 239\n",
    "    df.loc[58813, 'question'] = 'How is public spending distributed in Spain?'\n",
    "    df.loc[58813, 'text'] = 'the central government accounting for just 18% of public spending, 38% for the regional governments, 13% for the local councils, and the remaining 31% for the social security system'\n",
    "\n",
    "    df.loc[61893, 'answer_start'] = 101\n",
    "    df.loc[61893, 'text'] = 'Little'\n",
    "\n",
    "    df.loc[66861, 'answer_start'] = 520\n",
    "    df.loc[66861, 'text'] = 'parks, schools, public buildings, proper roads and the other amenities that characterise a modern city'\n",
    "\n",
    "    df.loc[68312, 'answer_start'] = 29\n",
    "    df.loc[68312, 'question'] = 'What occurs with osmotic diarrhea?'\n",
    "    df.loc[68312, 'text'] = 'too much water is drawn into the bowels'\n",
    "\n",
    "    df.loc[70195, 'answer_start'] = 427\n",
    "    df.loc[70195, 'questions'] = \"What did the Native American tribes fail to accomplish in the later Pontiac's War?\"\n",
    "    df.loc[70195, 'text'] = 'returning them to their pre-war status'\n",
    "\n",
    "    df.loc[70443, 'answer_start'] = 495\n",
    "    df.loc[70443, 'text'] = 'somehow-belligerent'\n",
    "\n",
    "    df.loc[71357, 'answer_start'] = 118\n",
    "    df.loc[71357, 'text'] = 'science-fiction and adventure'\n",
    "\n",
    "    df.loc[75502, 'text'] = '140 million'\n",
    "    df.loc[75502, 'answer_start'] = 389\n",
    "\n",
    "    df.loc[85016, 'answer_start'] = 387\n",
    "\n",
    "    df.loc[85004, 'question'] = \"What was Greece's reference year budget deficit?\"\n",
    "    df.loc[85004, 'text'] = '3.38% of GDP'\n",
    "    df.loc[85004, 'answer_start'] = 385\n",
    "\n",
    "    df.loc[85016, 'text'] = \"this affected deficit values after 2001 (when Greece had already been admitted into the Eurozone)\"\n",
    "    df.loc[85016, 'answer_start'] = 363\n",
    "\n",
    "    df.loc[87208, 'text'] = \"typically discarded\"\n",
    "    df.loc[87208, 'answer_start'] = 216\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_stanford_qa_data():\n",
    "    # thanks to Bharath, https://www.kaggle.com/bharathsh/stanford-q-a-json-to-clean-dataframe,\n",
    "    # for code adapted for this use\n",
    "    #\n",
    "    train_path = os.path.join(STANFORD_DATA_PATH, 'train-v1.1.json')\n",
    "    path = ['data', 'paragraphs', 'qas', 'answers']\n",
    "    with open(train_path) as fh:\n",
    "        raw_json = json.loads(fh.read())\n",
    "\n",
    "    js = pd.io.json.json_normalize(raw_json, path)\n",
    "    m = pd.io.json.json_normalize(raw_json, path[:-1])\n",
    "    r = pd.io.json.json_normalize(raw_json, path[:-2])\n",
    "\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "    ndx = np.repeat(m['id'].values, m['answers'].str.len())\n",
    "    m['context'] = idx\n",
    "    js['q_idx'] = ndx\n",
    "\n",
    "    df = pd.concat([\n",
    "        m[['id', 'question', 'context']].set_index('id'),\n",
    "        js.set_index('q_idx')], 1).reset_index()\n",
    "\n",
    "    df['c_id'] = df['context'].factorize()[0]\n",
    "    df.head()\n",
    "    df = one_off_corrections(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = import_stanford_qa_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "      <th>c_id</th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>381</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>92</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             context  answer_start  \\\n",
       "0  Architecturally, the school has a Catholic cha...           515   \n",
       "1  Architecturally, the school has a Catholic cha...           188   \n",
       "2  Architecturally, the school has a Catholic cha...           279   \n",
       "3  Architecturally, the school has a Catholic cha...           381   \n",
       "4  Architecturally, the school has a Catholic cha...            92   \n",
       "\n",
       "                                      text  c_id questions  \n",
       "0               Saint Bernadette Soubirous     0       NaN  \n",
       "1                a copper statue of Christ     0       NaN  \n",
       "2                        the Main Building     0       NaN  \n",
       "3  a Marian place of prayer and reflection     0       NaN  \n",
       "4       a golden statue of the Virgin Mary     0       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87587, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87587"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['answer_sent'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "      <th>c_id</th>\n",
       "      <th>questions</th>\n",
       "      <th>answer_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>381</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>92</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             context  answer_start  \\\n",
       "0  Architecturally, the school has a Catholic cha...           515   \n",
       "1  Architecturally, the school has a Catholic cha...           188   \n",
       "2  Architecturally, the school has a Catholic cha...           279   \n",
       "3  Architecturally, the school has a Catholic cha...           381   \n",
       "4  Architecturally, the school has a Catholic cha...            92   \n",
       "\n",
       "                                      text  c_id questions answer_sent  \n",
       "0               Saint Bernadette Soubirous     0       NaN        None  \n",
       "1                a copper statue of Christ     0       NaN        None  \n",
       "2                        the Main Building     0       NaN        None  \n",
       "3  a Marian place of prayer and reflection     0       NaN        None  \n",
       "4       a golden statue of the Virgin Mary     0       NaN        None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['context'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "      <th>c_id</th>\n",
       "      <th>questions</th>\n",
       "      <th>answer_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>381</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>92</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             context  answer_start  \\\n",
       "0  Architecturally, the school has a Catholic cha...           515   \n",
       "1  Architecturally, the school has a Catholic cha...           188   \n",
       "2  Architecturally, the school has a Catholic cha...           279   \n",
       "3  Architecturally, the school has a Catholic cha...           381   \n",
       "4  Architecturally, the school has a Catholic cha...            92   \n",
       "\n",
       "                                      text  c_id questions answer_sent  \n",
       "0               Saint Bernadette Soubirous     0       NaN        None  \n",
       "1                a copper statue of Christ     0       NaN        None  \n",
       "2                        the Main Building     0       NaN        None  \n",
       "3  a Marian place of prayer and reflection     0       NaN        None  \n",
       "4       a golden statue of the Virgin Mary     0       NaN        None  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context'].str.startswith(\"Architecturally, the school has a Catholic character\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One of the main driving forces in the growth of the University was its football team, the Notre Dame Fighting Irish. Knute Rockne became head coach in 1918. Under Rockne, the Irish would post a record of 105 wins, 12 losses, and five ties. During his 13 years the Irish won three national championships, had five undefeated seasons, won the Rose Bowl in 1925, and produced players such as George Gipp and the \"Four Horsemen\". Knute Rockne has the highest winning percentage (.881) in NCAA Division I/FBS football history. Rockne\\'s offenses employed the Notre Dame Box and his defenses ran a 7–2–2 scheme. The last game Rockne coached was on December 14, 1930 when he led a group of Notre Dame all-stars against the New York Giants in New York City.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['context'].loc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "      <th>c_id</th>\n",
       "      <th>questions</th>\n",
       "      <th>answer_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>573387acd058e614000b5cb1</td>\n",
       "      <td>The Notre Dame football team got a new head co...</td>\n",
       "      <td>One of the main driving forces in the growth o...</td>\n",
       "      <td>117</td>\n",
       "      <td>Knute Rockne</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>573387acd058e614000b5cb2</td>\n",
       "      <td>What was the amount of wins Knute Rockne attai...</td>\n",
       "      <td>One of the main driving forces in the growth o...</td>\n",
       "      <td>204</td>\n",
       "      <td>105</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>573387acd058e614000b5cb5</td>\n",
       "      <td>In what year did the team lead by Knute Rockne...</td>\n",
       "      <td>One of the main driving forces in the growth o...</td>\n",
       "      <td>354</td>\n",
       "      <td>1925</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>573387acd058e614000b5cb3</td>\n",
       "      <td>How many years was Knute Rockne head coach at ...</td>\n",
       "      <td>One of the main driving forces in the growth o...</td>\n",
       "      <td>251</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>573387acd058e614000b5cb4</td>\n",
       "      <td>How many national titles were won when Knute R...</td>\n",
       "      <td>One of the main driving forces in the growth o...</td>\n",
       "      <td>274</td>\n",
       "      <td>three</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        index  \\\n",
       "98   573387acd058e614000b5cb1   \n",
       "99   573387acd058e614000b5cb2   \n",
       "100  573387acd058e614000b5cb5   \n",
       "101  573387acd058e614000b5cb3   \n",
       "102  573387acd058e614000b5cb4   \n",
       "\n",
       "                                              question  \\\n",
       "98   The Notre Dame football team got a new head co...   \n",
       "99   What was the amount of wins Knute Rockne attai...   \n",
       "100  In what year did the team lead by Knute Rockne...   \n",
       "101  How many years was Knute Rockne head coach at ...   \n",
       "102  How many national titles were won when Knute R...   \n",
       "\n",
       "                                               context  answer_start  \\\n",
       "98   One of the main driving forces in the growth o...           117   \n",
       "99   One of the main driving forces in the growth o...           204   \n",
       "100  One of the main driving forces in the growth o...           354   \n",
       "101  One of the main driving forces in the growth o...           251   \n",
       "102  One of the main driving forces in the growth o...           274   \n",
       "\n",
       "             text  c_id questions answer_sent  \n",
       "98   Knute Rockne    20       NaN        None  \n",
       "99            105    20       NaN        None  \n",
       "100          1925    20       NaN        None  \n",
       "101            13    20       NaN        None  \n",
       "102         three    20       NaN        None  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context'].str.startswith(\"One of the main driving forces in the growth of the\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'Super_Bowl_50', 'paragraphs': [{'co...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Warsaw', 'paragraphs': [{'context':...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Normans', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'Nikola_Tesla', 'paragraphs': [{'con...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'Computational_complexity_theory', '...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  version\n",
       "0  {'title': 'Super_Bowl_50', 'paragraphs': [{'co...      1.1\n",
       "1  {'title': 'Warsaw', 'paragraphs': [{'context':...      1.1\n",
       "2  {'title': 'Normans', 'paragraphs': [{'context'...      1.1\n",
       "3  {'title': 'Nikola_Tesla', 'paragraphs': [{'con...      1.1\n",
       "4  {'title': 'Computational_complexity_theory', '...      1.1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanmay/python3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/tanmay/python3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for row_idx in range(train.shape[0]):\n",
    "    y = train['text'][row_idx]\n",
    "    try:\n",
    "        list_idx = [(y in x) for x in sent_tokenize(train['context'][row_idx])].index(True)\n",
    "        ans_sent = sent_tokenize(train['context'][row_idx])[list_idx]\n",
    "        train['answer_sent'][row_idx] = ans_sent\n",
    "    except:\n",
    "        train['answer_sent'][row_idx] = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "      <th>c_id</th>\n",
       "      <th>questions</th>\n",
       "      <th>answer_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is a replica of the grotto at Lourdes, Fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>381</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Immediately behind the basilica is the Grotto,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>92</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             context  answer_start  \\\n",
       "0  Architecturally, the school has a Catholic cha...           515   \n",
       "1  Architecturally, the school has a Catholic cha...           188   \n",
       "2  Architecturally, the school has a Catholic cha...           279   \n",
       "3  Architecturally, the school has a Catholic cha...           381   \n",
       "4  Architecturally, the school has a Catholic cha...            92   \n",
       "\n",
       "                                      text  c_id questions  \\\n",
       "0               Saint Bernadette Soubirous     0       NaN   \n",
       "1                a copper statue of Christ     0       NaN   \n",
       "2                        the Main Building     0       NaN   \n",
       "3  a Marian place of prayer and reflection     0       NaN   \n",
       "4       a golden statue of the Virgin Mary     0       NaN   \n",
       "\n",
       "                                         answer_sent  \n",
       "0  It is a replica of the grotto at Lourdes, Fran...  \n",
       "1  Immediately in front of the Main Building and ...  \n",
       "2  Atop the Main Building's gold dome is a golden...  \n",
       "3  Immediately behind the basilica is the Grotto,...  \n",
       "4  Atop the Main Building's gold dome is a golden...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"/home/tanmay/Documents/learnogether/data/qna/qna_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['answer_sent'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train['answer_sent'].isna().sum()\n",
    "old one contained 216 NaN values..b4 substituting one_off_corrections function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lCkP3IkxAU4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saint Bernadette Soubirous'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "tensorflow QnA with NMT Baseline.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
